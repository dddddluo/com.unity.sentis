{
  "name": "com.unity.sentis",
  "displayName": "Sentis",
  "version": "1.4.0-pre.1",
  "unity": "2023.2",
  "description": "Sentis is a neural network inference library. It enables you to import trained neural network models, connect the network inputs and outputs to your game code, and then run them locally in your end-user app. Use cases include capabilities like natural language processing, object recognition, automated game opponents, sensor data classification, and many more.\n\nSentis automatically optimizes your network for real-time use to speed up inference. It also allows you to tune your implementation further with tools like frame slicing, quantization, and custom backend (i.e. compute type) dispatching.\n\nVisit https://unity.com/sentis for more resources.",
  "dependencies": {
    "com.unity.burst": "1.8.12",
    "com.unity.collections": "1.2.4",
    "com.unity.modules.jsonserialize": "1.0.0",
    "com.unity.modules.imageconversion": "1.0.0"
  },
  "_upm": {
    "changelog": "### Added\n- Fast path for Scatter and Gather ops.\n- Quantization API for quantizing model weights to Float16 or Uint8.\n- TensorByte and TensorShort tensor types for quantization.\n- Pad operator to support 'axes' input, 'TensorInt' input and 'wrap' mode.\n- GeluFast op for tiny stories optimization.\n- Tensor 'Reshape' method for changing shape without backend.\n- Functional API for compiling models with torch-like syntax.\n- Analytics reporting on model import.\n\n### Changed\n- Reworked async API with awaitable methods on tensor readback.\n- Reworked tensor allocation scheme.\n- Renamed tensor fields and methods.\n- Reworked model serialization to use flatbuffers.\n- Random layers accept integer seed rather than float.\n- Improved NonMaxSuppression inference drastically and added GPUCompute backend.\n\n### Fixed\n- Dispatch limit issues on Split operator.\n- Optimization pass where Dense has transposed weights.\n- Import settings for Resize op on opset 10.\n- Links to external sources in docs.\n- Edge cases in ScatterElements and GatherElements infer correctly.\n- Conv operator going out of bounds on GPUCompute and GPUCommandBuffer.\n\n### Removed\n- Broken optimization pass for Dense > ScaleBias.\n- ArrayTensorData class and methods.\n- 'CreateWorker' method from model extensions.\n- Mapping of param symbolic tensor dims to original names.\n- Model API for adding inputs, constants, layers to model (in favour of Functional API).\n- Ops for tensor operations (in favour of Functional API)."
  },
  "upmCi": {
    "footprint": "37efed2c75d71a402f23e53449a6be1f1e848f4c"
  },
  "documentationUrl": "https://docs.unity3d.com/Packages/com.unity.sentis@1.4/manual/index.html",
  "repository": {
    "url": "https://github.cds.internal.unity3d.com/unity/UnityInferenceEngine.git",
    "type": "git",
    "revision": "aa807c1cb80872b70ccb2ac84e90f63a9d771ce3"
  },
  "samples": [
    {
      "displayName": "Convert tensors to textures",
      "description": "Examples of converting tensors to textures.",
      "path": "Samples~/Convert tensors to textures"
    },
    {
      "displayName": "Convert textures to tensors",
      "description": "Examples of converting textures to textures.",
      "path": "Samples~/Convert textures to tensors"
    },
    {
      "displayName": "Copy a texture tensor to the screen",
      "description": "An example of using TextureConverter.RenderToScreen to copy a texture tensor to the screen.",
      "path": "Samples~/Copy a texture tensor to the screen"
    },
    {
      "displayName": "Do an operation on a tensor",
      "description": "An example of using `IBackend` to do an operation on a tensor.",
      "path": "Samples~/Do an operation on a tensor"
    },
    {
      "displayName": "Encrypt a model",
      "description": "Example of serializing an encrypted model to disk using a custom editor window and loading that encrypted model at runtime.",
      "path": "Samples~/Encrypt a model"
    },
    {
      "displayName": "Quantize a model",
      "description": "Example of serializing a quantized model to disk using a custom editor window and loading that quantized model at runtime.",
      "path": "Samples~/Quantize a model"
    },
    {
      "displayName": "Read output asynchronously",
      "description": "Examples of reading the output from a model asynchronously, using compute shaders or Burst.",
      "path": "Samples~/Read output asynchronously"
    },
    {
      "displayName": "Run a model",
      "description": "Examples of running models with different numbers of inputs and outputs.",
      "path": "Samples~/Run a model"
    },
    {
      "displayName": "Run a model a layer at a time",
      "description": "An example of using StartManualSchedule to run a model a layer a time.",
      "path": "Samples~/Run a model a layer at a time"
    },
    {
      "displayName": "Use Burst to write data",
      "description": "An example of using Burst to write data to a tensor in the Job system.",
      "path": "Samples~/Use Burst to write data"
    },
    {
      "displayName": "Use a compute buffer",
      "description": "An example of using a compute shader to write data to a tensor on the GPU.",
      "path": "Samples~/Use a compute buffer"
    },
    {
      "displayName": "Use tensor indexing methods",
      "description": "Examples of using tensor indexing methods to get and set tensor values.",
      "path": "Samples~/Use tensor indexing methods"
    },
    {
      "displayName": "Use the functional API with an existing model",
      "description": "An example of using the functional API to extend an existing model.",
      "path": "Samples~/Use the functional API with an existing model"
    }
  ]
}
